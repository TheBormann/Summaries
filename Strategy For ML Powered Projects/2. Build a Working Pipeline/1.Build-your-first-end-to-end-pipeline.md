# Build your first end-to-end pipeline

The general strategy is to start with the inference pipeline, to see if the end product is viable or not.
That means, build the basic inference pipeline (It only need the core features) use heuristics as a simple and fast
implementable type of model and test your pipeline.
If the test works, you can gather data about the usefulness of the product and it's easier to define which improvement 
has the most effect. (impact bottleneck)

## The Simplest Scaffolding
As I said above, it is very important to create a usable product first, before diving into any improvements!

## For an example on how to create such a product see:
[Building Machine Learning Powered Applications](https://www.oreilly.com/library/view/building-machine-learning/9781492045106/)
page 48

## Test your workflow
â€œFrequently, your product is dead even if your
model is successful."

### User Experience
Is the projects implementation, regardless of the accuracy even a good product, that users want to use?

### Modeling Results
How good is the baseline-model and how can we iterate on that to improve it?

Discounted cumulative gain (DCG) rates the different outputs for relevancy and spits the top ones out

#### Finding the impact bottleneck

* On the product side
* On the model side

If we can't get the desired result, is it possible to find an alternative, that works good?
For example, if you can't generate better questions, maybe you can pin down where the written question is badly written and how to solve it.


   