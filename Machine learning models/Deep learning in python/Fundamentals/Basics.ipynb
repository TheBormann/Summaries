{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "collapsed": true,
    "pycharm": {
     "name": "#%% md\n"
    }
   },
   "source": [
    "# Basics of Deep learning\n",
    "Deep learning is a subset of machine learning.\n",
    "This means with deep learning we are implementing algorithms that learn from data and make predictions out of it.\n",
    "(Disclamer: Resource the summary is based on the [www.deeplizard.com](https://deeplizard.com/learn/video/gZmobeGL0Yg) website)\n",
    "\n",
    "Deep learning itself can split up into **supervised learning** and **unsupervised learning**\n",
    "\n",
    "* **Supervised learning** means, that the algorithms learn from already classified data\n",
    "* **Unsupervised learning** means, the algorithm is trying to group similar inputs together to predict to correct outcome.\n",
    "\n",
    "### Load data\n",
    "\n",
    "It is very important to divide your data into 3 parts\n",
    "1. **Training**: used to let the data learn from\n",
    "2. **Validation**: used to evaluate if the training was effective\n",
    "3 **Testing**: After the training cycle is complete, we can use the testing set, to see if the model can be used in production.\n",
    "    You need this separation, because the Validation set is part of the training process and you **shouldn't** mix training\n",
    "    data with validation data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "\n",
    "df_np = np.loadtxt('./Dataset/pima-indians-diabetes.csv', delimiter=',')\n",
    "X = df_np[:, 0:8]\n",
    "y = df_np[:, 8]\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Artificial Neural Networks\n",
    "Artificial neural networks are based on the concept of how human brains work.\n",
    "This means they compute the output based on the collection of connected neurons that are organized in layers\n",
    "\n",
    "Layers are generally divided into **Input layer**(Where the values are feed in), the **Hidden layer** (Where the transformation happens)\n",
    "and the **Output layer**(Where a result is formed).\n",
    "Additionally there are different types of how the layers are connected to each other. For example:\n",
    "* **Dense layer** Each output is generated using every input to the layer\n",
    "* **Convolutional layers**\n",
    "* **Pooling layers**\n",
    "* **Recurrent layers**\n",
    "* **Normalization layers**\n",
    "But more on them later.\n",
    "\n",
    "We are using Keras to generate quick neural networks that perform the discussed algorithms.\n",
    "The **Sequential** model is Keras implementation of an ANN (artificial neural network):"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "outputs": [],
   "source": [
    "import tensorflow\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense, Activation\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "\n",
    "\n",
    "model = Sequential([\n",
    "    Dense(12, input_shape=(8,), activation='relu'),\n",
    "    Dense(8, activation=\"relu\"),\n",
    "    Dense(2, activation='softmax'),\n",
    "])\n",
    "\n",
    "# Define training process\n",
    "model.compile(Adam(lr=.0001), loss='sparse_categorical_crossentropy', metrics=['accuracy'])\n",
    "\n",
    "model.summary()"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "What this code is describing, is that we have the model takes an input with 10 columns.\n",
    "The Activation function will be discussed later but it decides, how the values should be transformed to generate the output values\n",
    "for the layer.\n",
    "The dense layer was already discussed above.\n",
    "\n",
    "The Neural Net is generally functioning like this:\n",
    "Every Node is connected to nodes in the next layer. Because each connection has a different strength, the input values have\n",
    "a different amount of impact in the next layer. each nodes adds each value together and transforms it with an activation function.\n",
    "After that the output value is passed to the next node.\n",
    "While training the Model, the \"Weights\"(which are the strength of each connection) are updated, to generate better results.\n",
    "\n",
    "The compile method defines with what parameters the training should be performed.\n",
    "First we define the **optimizer**, which will change how the weights are updated.\n",
    "More on how they work [here](Optimization_Algorithms.ipynb)\n",
    "\n",
    "Next we define the **loss function** it will calculate how high the error rate of the algorithm is.\n",
    "A typical loss function is \"mean squared error (MSE)\", which squared the errors and gets the mean out of it.\n",
    "For more detail read [here](Loss_Functions.ipynb)\n",
    "\n",
    "The metric Parameter only lets us add additional information, that should be displayed while training, like the accuracy.\n",
    "\n",
    "## Activation Function\n",
    "The activation function is a way to remap the input values a node gets.\n",
    "For example:\n",
    "* **Sigmoid function** takes any value and transforms it into an value between 0 and 1, where negative values are closer to 0 and posititve\n",
    "    values are closer to 1\n",
    "* **Relu function** maps the value to its actual value, as long as it is positive, otherwise it give 0 back.\n",
    "\n",
    "## Train an AI model\n",
    "\n",
    "Training a model is actually soling an optimisation problem. It means, for with weight values is the error rate the lowest?\n",
    "This means we try to apply methods like Stochastic Gradient Descent (SGD) to minimize the loss function.\n",
    "Now we are running the real training:"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "outputs": [
    {
     "data": {
      "text/plain": "<tensorflow.python.keras.callbacks.History at 0x2dc26711488>"
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.fit(x=X, y=y, batch_size=10, epochs=150, shuffle=True, verbose=0)"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "## Evaluate Model"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "768/768 [==============================] - 0s 78us/sample - loss: 0.6023 - accuracy: 0.7201\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\b\n",
      "Accuracy: 72.01\n"
     ]
    }
   ],
   "source": [
    "_, accuracy = model.evaluate(X, y)\n",
    "print('Accuracy: %.2f' % (accuracy*100))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "## Predictions"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[6.0, 148.0, 72.0, 35.0, 0.0, 33.6, 0.627, 50.0] => 1 (expected 1)\n",
      "[1.0, 85.0, 66.0, 29.0, 0.0, 26.6, 0.351, 31.0] => 0 (expected 0)\n",
      "[8.0, 183.0, 64.0, 0.0, 0.0, 23.3, 0.672, 32.0] => 1 (expected 1)\n",
      "[1.0, 89.0, 66.0, 23.0, 94.0, 28.1, 0.167, 21.0] => 0 (expected 0)\n",
      "[0.0, 137.0, 40.0, 35.0, 168.0, 43.1, 2.288, 33.0] => 1 (expected 1)\n"
     ]
    }
   ],
   "source": [
    "# predicts values and puts them into classes\n",
    "predictions = model.predict_classes(X)\n",
    "\n",
    "# summarize the first 5 cases\n",
    "for i in range(5):\n",
    "\tprint('%s => %d (expected %d)' % (X[i].tolist(), predictions[i], y[i]))"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%%\n"
    }
   }
  },
  {
   "cell_type": "markdown",
   "source": [
    "\n",
    "\n",
    "\n",
    "\n"
   ],
   "metadata": {
    "collapsed": false,
    "pycharm": {
     "name": "#%% md\n"
    }
   }
  }
 ],
 "metadata": {
  "kernelspec": {
   "name": "python3",
   "language": "python",
   "display_name": "Python 3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}